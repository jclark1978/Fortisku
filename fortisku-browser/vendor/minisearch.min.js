/**
 * MiniSearch (lightweight implementation)
 * Provides client-side full text search with prefix and AND support.
 * This implementation focuses on the subset of capabilities required by FortiSKU Finder.
 */
function defaultProcessTerm(term) {
  return term.normalize("NFKD").replace(/[\u0300-\u036f]/g, "").toLowerCase();
}

function defaultTokenize(text) {
  if (text === undefined || text === null) {
    return [];
  }
  const normalized = String(text)
    .normalize("NFKD")
    .replace(/[\u0300-\u036f]/g, " ")
    .toLowerCase();
  return normalized.split(/[^a-z0-9]+/).filter(Boolean);
}

class BitSet {
  constructor() {
    this.map = new Map();
  }

  add(key) {
    this.map.set(key, true);
  }

  has(key) {
    return this.map.has(key);
  }

  values() {
    return this.map.keys();
  }
}

export class MiniSearch {
  constructor(options = {}) {
    const {
      fields = [],
      storeFields = [],
      idField = "id",
      tokenize = defaultTokenize,
      processTerm = defaultProcessTerm,
      searchOptions = {}
    } = options;

    this._options = {
      fields,
      storeFields,
      idField,
      tokenize,
      processTerm,
      searchOptions
    };

    this._index = new Map(); // term -> Map<docId, frequency>
    this._docFreqs = new Map(); // term -> doc frequency
    this._documents = new Map(); // docId -> original doc
    this._storedFields = new Map(); // docId -> storedFields object
    this._terms = new BitSet();
  }

  add(document) {
    const id = document[this._options.idField];
    if (id === undefined || id === null) {
      throw new Error(`Document is missing id field "${this._options.idField}".`);
    }

    const tokenFrequencies = new Map();
    for (const fieldName of this._options.fields) {
      const value = document[fieldName];
      const tokens = this._options.tokenize(value);
      for (const token of tokens) {
        const processed = this._options.processTerm(token);
        if (!processed) continue;
        const key = `${fieldName}:${processed}`;
        tokenFrequencies.set(key, (tokenFrequencies.get(key) || 0) + 1);
      }
    }

    this._documents.set(id, document);

    const stored = {};
    for (const fieldName of this._options.storeFields) {
      stored[fieldName] = document[fieldName];
    }
    this._storedFields.set(id, stored);

    for (const [term, frequency] of tokenFrequencies.entries()) {
      if (!this._index.has(term)) {
        this._index.set(term, new Map());
      }
      const postings = this._index.get(term);
      postings.set(id, frequency);
      this._terms.add(term);

      const docFreq = this._docFreqs.get(term) || 0;
      this._docFreqs.set(term, docFreq + 1);
    }
  }

  addAll(documents) {
    for (const doc of documents) {
      this.add(doc);
    }
  }

  search(query, options = {}) {
    const config = {
      combineWith: "OR",
      prefix: false,
      ...this._options.searchOptions,
      ...options
    };

    const queryTokens = this._options.tokenize(query).map((token) => this._options.processTerm(token));
    const tokens = queryTokens.filter(Boolean);
    if (!tokens.length) {
      return [];
    }

    const docScores = new Map();
    const totalDocs = this._documents.size || 1;

    for (const token of tokens) {
      const matchingTerms = this._matchingTerms(token, config.prefix);
      const matches = new Map();

      for (const term of matchingTerms) {
        const postings = this._index.get(term);
        if (!postings) continue;

        const docFreq = this._docFreqs.get(term) || 1;
        const idf = Math.log(1 + totalDocs / docFreq);

        for (const [docId, freq] of postings.entries()) {
          if (!matches.has(docId)) {
            matches.set(docId, []);
          }
          matches.get(docId).push({ term, freq, idf });
        }
      }

      if (config.combineWith === "AND") {
        if (!docScores.size) {
          for (const [docId, hitList] of matches.entries()) {
            const score = hitList.reduce((sum, hit) => sum + hit.freq * hit.idf, 0);
            docScores.set(docId, {
              score,
              terms: new Set(hitList.map((hit) => hit.term))
            });
          }
        } else {
          for (const docId of Array.from(docScores.keys())) {
            if (!matches.has(docId)) {
              docScores.delete(docId);
              continue;
            }
            const hitList = matches.get(docId);
            const score = hitList.reduce((sum, hit) => sum + hit.freq * hit.idf, 0);
            const existing = docScores.get(docId);
            existing.score += score;
            hitList.forEach((hit) => existing.terms.add(hit.term));
          }
        }
      } else {
        for (const [docId, hitList] of matches.entries()) {
          const score = hitList.reduce((sum, hit) => sum + hit.freq * hit.idf, 0);
          if (!docScores.has(docId)) {
            docScores.set(docId, { score, terms: new Set(hitList.map((hit) => hit.term)) });
          } else {
            const entry = docScores.get(docId);
            entry.score += score;
            hitList.forEach((hit) => entry.terms.add(hit.term));
          }
        }
      }
    }

    const results = Array.from(docScores.entries())
      .map(([docId, data]) => ({
        id: docId,
        score: data.score,
        terms: Array.from(data.terms),
        document: this._storedFields.get(docId)
      }))
      .sort((a, b) => b.score - a.score);

    return results;
  }

  toJSON() {
    return {
      version: 1,
      options: {
        fields: this._options.fields,
        storeFields: this._options.storeFields,
        idField: this._options.idField
      },
      index: Array.from(this._index.entries()).map(([term, postings]) => [
        term,
        Array.from(postings.entries())
      ]),
      docFreqs: Array.from(this._docFreqs.entries()),
      storedFields: Array.from(this._storedFields.entries())
    };
  }

  static loadJSON(serialized, overrides = {}) {
    const instance = new MiniSearch({
      ...serialized.options,
      ...overrides
    });

    instance._index = new Map(serialized.index.map(([term, entries]) => [term, new Map(entries)]));
    instance._docFreqs = new Map(serialized.docFreqs);
    instance._storedFields = new Map(serialized.storedFields);
    instance._documents = new Map(serialized.storedFields);
    instance._terms = new BitSet();
    for (const term of instance._index.keys()) {
      instance._terms.add(term);
    }
    return instance;
  }

  _matchingTerms(token, prefix) {
    const matches = [];
    if (prefix) {
      for (const term of this._terms.values()) {
        if (term.endsWith(`:${token}`) || term.includes(`:${token}`)) {
          const [, processedToken] = term.split(":");
          if (processedToken.startsWith(token)) {
            matches.push(term);
          }
        }
      }
    } else {
      for (const term of this._terms.values()) {
        if (term.endsWith(`:${token}`)) {
          matches.push(term);
        }
      }
    }
    return matches;
  }
}

export default MiniSearch;
